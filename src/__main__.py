# Ð¢Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð° Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹: python -m src
import os
import asyncio
import aiohttp
import time
from dataclasses import dataclass
from datetime import date, timedelta
from aiogram import Bot, Dispatcher, types
from aiogram.dispatcher.event.bases import SkipHandler
from aiogram.filters import CommandStart, Command
from aiogram.types import ChatMemberUpdated, ChatMember

from .context_pipeline import build_context, ContextConfig
from .humor_gate import should_add_humor, HumorConfig
from .memory_store import MemoryStore, naive_summarizer

# Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ñ€Ð¸Ð´ÑƒÑ‚ Ð¸Ð· .env (Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ)
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OLLAMA = os.getenv("OLLAMA_ENDPOINT", "http://host.docker.internal:11434")
MODEL = os.getenv("MODEL_NAME", "qwen2.5:7b-instruct-q4_K_M")

# Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚, Ð·Ð°Ð´Ð°ÐµÑ‚ÑÑ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ
SYSTEM_PROMPT = os.getenv(
    "SYSTEM_PROMPT",
    "Ð¢Ñ‹ â€” Ð¿Ð¾Ð»Ð½Ð¾Ñ†ÐµÐ½Ð½Ñ‹Ð¹ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸Ðº Ñ‡Ð°Ñ‚Ð°. ÐŸÐ¸ÑˆÐ¸ Ð¶Ð¸Ð²Ð¾, Ð¿Ð¾â€‘Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÐºÐ¸, ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ. "
    "Ð¡Ñ‚Ð¸Ð»ÑŒ: Ð¶Ñ‘ÑÑ‚ÐºÐ¾â€‘ÑÐ°Ñ€ÐºÐ°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹, ÑƒÐ³Ð°Ñ€Ð½Ñ‹Ð¹, Ð´Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑˆÑŒ Ð³Ñ€ÑƒÐ±Ð¾ÑÑ‚ÑŒ Ð¸ Ð¼Ð°Ñ‚, ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ. "
    "ÐÐµ ÑÐ¿Ð°Ð¼ÑŒ ÑˆÑƒÑ‚ÐºÐ°Ð¼Ð¸: Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð¾Ð´Ð½Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ ÑˆÑƒÑ‚ÐºÐ° Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ðµ Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ðº Ð¼ÐµÑÑ‚Ñƒ. "
    "Ð”ÐµÑ€Ð¶Ð¸ Ð¼Ñ‹ÑÐ»ÑŒ, Ð½Ðµ ÑƒÐ²Ð¾Ð´Ð¸ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€ Ð² ÑÑ‚Ð¾Ñ€Ð¾Ð½Ñƒ, Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ñ„Ð°ÐºÑ‚Ñ‹. "
    "Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ ÑÐµÑ€ÑŒÑ‘Ð·Ð½Ñ‹Ð¹ â€” Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ ÑÐµÑ€ÑŒÑ‘Ð·Ð½Ð¾, Ð±ÐµÐ· Ð³Ð»ÑƒÐ¼Ð°. "
    "Ð•ÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð½ÐµÑ‡ÐµÐ³Ð¾ â€” Ð»ÑƒÑ‡ÑˆÐµ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð¹ ÑÑ‚Ð¾, Ñ‡ÐµÐ¼ Ð½ÐµÑÑ‚Ð¸ Ñ‡ÑƒÑˆÑŒ."
)

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ chat API
USE_CHAT_API = os.getenv("USE_CHAT_API", "true").lower() == "true"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.getenv("DATA_DIR", os.path.join(BASE_DIR, "..", "data"))
os.makedirs(DATA_DIR, exist_ok=True)
DB_PATH = os.getenv("MEMORY_DB_PATH", os.path.join(DATA_DIR, "bot_memory.sqlite"))

store = MemoryStore(DB_PATH)


@dataclass
class SessionState:
    last_humor_ts: float | None = None
    last_summary_day: date | None = None
    last_joke_day: date | None = None
    jokes_today: int = 0
    last_maintenance_day: date | None = None
    last_vacuum_day: date | None = None


def _get_state(chat_id: str, state_by_chat: dict) -> SessionState:
    state = state_by_chat.get(chat_id)
    if state is None:
        state = SessionState()
        state_by_chat[chat_id] = state
    return state


def _maybe_summarize(chat_id: str, state: SessionState) -> None:
    day = date.today() - timedelta(days=1)
    if state.last_summary_day == day:
        return
    store.summarize_day(chat_id, day, naive_summarizer)
    state.last_summary_day = day


def _maybe_maintenance(chat_id: str, state: SessionState) -> None:
    today = date.today()
    if state.last_maintenance_day != today:
        state.last_maintenance_day = today
        keep_msgs_days = int(os.getenv("MEMORY_KEEP_DAYS", "14"))
        keep_sum_days = int(os.getenv("MEMORY_SUMMARY_KEEP_DAYS", "60"))
        store.prune_old_messages(keep_msgs_days)
        store.prune_old_summaries(keep_sum_days)

    vacuum_weekday = int(os.getenv("MEMORY_VACUUM_WEEKDAY", "6"))
    if today.weekday() != vacuum_weekday:
        return
    if state.last_vacuum_day == today:
        return
    state.last_vacuum_day = today
    store.vacuum()


def _is_question(text: str) -> bool:
    return "?" in text


bot = Bot(TELEGRAM_TOKEN)
dp = Dispatcher()
state_by_chat: dict[str, SessionState] = {}
BOT_ID: int | None = None

@dp.message(CommandStart())
async def start(msg: types.Message):
    await msg.answer("ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ð½Ð° Ð¼ÐµÑÑ‚Ðµ. Ð¡Ð¿Ñ€Ð¾ÑÐ¸ Ð¼ÐµÐ½Ñ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ.")

@dp.message(Command("help"))
async def help_command(msg: types.Message):
    help_text = """
ðŸ¤– **ÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ñ‚Ð°:**

1. **Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð¼ÐµÐ½Ñ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ** - Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽ Ð²ÑÐµÑ…
2. **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ** Ð² Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð»ÑŽÐ±Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ðµ
3. **Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:**
   - `/start` - Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ
   - `/help` - ÑÑ‚Ð° ÑÐ¿Ñ€Ð°Ð²ÐºÐ°
   - `/ping` - Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð±Ð¾Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚

ðŸ’¡ **Ð¡Ð¾Ð²ÐµÑ‚:** ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ (reply) Ð½Ð° Ð»ÑŽÐ±Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ðµ, Ð¸ Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ!
    """
    await msg.answer(help_text, parse_mode="Markdown")

@dp.message(Command("ping"))
async def ping_command(msg: types.Message):
    await msg.answer("ðŸ“ ÐŸÐ¾Ð½Ð³! Ð‘Ð¾Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚!")

@dp.message()
async def store_any_message(msg: types.Message):
    if msg.from_user and BOT_ID and msg.from_user.id == BOT_ID:
        return
    if (
        BOT_ID
        and msg.reply_to_message
        and msg.reply_to_message.from_user
        and msg.reply_to_message.from_user.id == BOT_ID
    ):
        raise SkipHandler
    text = msg.text or msg.caption or ""
    if not text.strip():
        return
    if text.strip().startswith("/"):
        return
    chat_id = str(msg.chat.id)
    msg_id = str(msg.message_id)
    state = _get_state(chat_id, state_by_chat)
    _maybe_summarize(chat_id, state)
    _maybe_maintenance(chat_id, state)
    store.add_message(chat_id, msg_id, "user", text)

    ambient_enabled = os.getenv("AMBIENT_JOKE_ENABLED", "true").lower() == "true"
    if not ambient_enabled:
        return
    if not _is_question(text):
        return

    today = date.today()
    if state.last_joke_day != today:
        state.last_joke_day = today
        state.jokes_today = 0

    max_per_day = int(os.getenv("AMBIENT_JOKE_MAX_PER_DAY", "4"))
    if state.jokes_today >= max_per_day:
        return

    humor_cfg = HumorConfig(
        humor_rate=float(os.getenv("AMBIENT_JOKE_RATE", "0.04")),
        min_gap_seconds=int(os.getenv("AMBIENT_JOKE_MIN_GAP_SECONDS", "1800")),
        min_length=int(os.getenv("HUMOR_MIN_LENGTH", "6")),
        max_length=int(os.getenv("HUMOR_MAX_LENGTH", "600")),
        block_keywords=tuple(
            k.strip().lower()
            for k in os.getenv("HUMOR_BLOCK_KEYWORDS", "").split(",")
            if k.strip()
        ),
    )
    if not should_add_humor(text, state.last_humor_ts, humor_cfg):
        return

    ctx_cfg = ContextConfig(
        recent_limit=int(os.getenv("RECENT_LIMIT", "40")),
        summary_days=int(os.getenv("SUMMARY_DAYS", "7")),
        max_summary_chars=int(os.getenv("SUMMARY_MAX_CHARS", "2000")),
        system_prompt=SYSTEM_PROMPT,
    )
    ctx = build_context(chat_id, text, store, ctx_cfg)
    ctx["messages"].append(
        {
            "role": "system",
            "content": (
                "Ð•ÑÐ»Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾, Ð²ÐºÐ¸Ð½ÑŒ Ð¾Ð´Ð½Ñƒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ ÑˆÑƒÑ‚ÐºÑƒ/Ð¿Ð¾Ð´ÐºÐ¾Ð» Ð² Ñ‡Ð°Ñ‚. "
                "Ð•ÑÐ»Ð¸ Ð½Ðµ Ðº Ð¼ÐµÑÑ‚Ñƒ â€” Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¾Ð»Ñ‡Ð¸."
            ),
        }
    )

    async with aiohttp.ClientSession() as session:
        if USE_CHAT_API:
            async with session.post(f"{OLLAMA}/api/chat", json={
                "model": MODEL,
                "messages": ctx["messages"],
                "stream": False,
                "temperature": 0.7,
            }) as r:
                data = await r.json()
                reply = data.get("message", {}).get("content", "").strip()
        else:
            async with session.post(f"{OLLAMA}/api/generate", json={
                "model": MODEL,
                "prompt": ctx["messages"][-1]["content"],
                "system": ctx["messages"][0]["content"],
                "stream": False,
                "temperature": 0.7,
            }) as r:
                data = await r.json()
                reply = data.get("response", "").strip()

    if not reply:
        return

    state.last_humor_ts = time.time()
    state.jokes_today += 1
    store.add_message(chat_id, msg_id + ":assistant", "assistant", reply)
    await msg.reply(reply)

@dp.chat_member()
async def on_chat_member_update(event: ChatMemberUpdated):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ/ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð±Ð¾Ñ‚Ð° Ð¸Ð· Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹"""
    if BOT_ID and event.new_chat_member.user.id == BOT_ID:
        if event.new_chat_member.status == ChatMember.MEMBER:
            # Ð‘Ð¾Ñ‚Ð° Ð´Ð¾Ð±Ð°Ð²Ð¸Ð»Ð¸ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ
            welcome_text = """
ðŸŽ‰ **ÐŸÑ€Ð¸Ð²ÐµÑ‚ Ð²ÑÐµÐ¼! Ð¯ Ð½Ð¾Ð²Ñ‹Ð¹ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸Ðº Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹!**

ðŸ¤– **ÐšÐ°Ðº ÑÐ¾ Ð¼Ð½Ð¾Ð¹ Ð¾Ð±Ñ‰Ð°Ñ‚ÑŒÑÑ:**
â€¢ ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ (reply) Ð½Ð° Ð»ÑŽÐ±Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ðµ
â€¢ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ `/help` Ð´Ð»Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ð¹ ÑÐ¿Ñ€Ð°Ð²ÐºÐ¸
â€¢ ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° `/ping` Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽ

Ð“Ð¾Ñ‚Ð¾Ð² Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð°ÑˆÐ¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹! ðŸš€
            """
            await event.chat.send_message(welcome_text, parse_mode="Markdown")
        elif event.new_chat_member.status == ChatMember.LEFT:
            # Ð‘Ð¾Ñ‚Ð° ÑƒÐ´Ð°Ð»Ð¸Ð»Ð¸ Ð¸Ð· Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹
            await event.chat.send_message("ðŸ‘‹ ÐŸÐ¾ÐºÐ° Ð²ÑÐµÐ¼! Ð‘Ñ‹Ð»Ð¾ Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾ Ð¿Ð¾Ð¾Ð±Ñ‰Ð°Ñ‚ÑŒÑÑ!")

@dp.message()
async def handle(msg: types.Message):
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ reply-ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
    if not msg.reply_to_message:
        return  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð±ÐµÐ· reply
    if not BOT_ID or not msg.reply_to_message.from_user or msg.reply_to_message.from_user.id != BOT_ID:
        return  # ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ€ÐµÐ¿Ð»Ð°Ð¸ Ð±Ð¾Ñ‚Ñƒ
    
    text = msg.text or msg.caption or ""
    if not text.strip():
        return
    if text == "Ð¿Ð¾ÑˆÑ‘Ð» Ð½Ð°Ñ…ÑƒÐ¹":
        await msg.answer("Ð¡Ð°Ð¼ Ð¿Ð¾ÑˆÑ‘Ð» Ð½Ð°Ñ…ÑƒÐ¹!")
        return
    if len(text) > 1000:
        await msg.answer("Ð¢Ñ‹ ÐµÐ±Ð»Ð°Ð½, Ð¿Ð¸ÑˆÐ¸ ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ!")
        return
    
    chat_id = str(msg.chat.id)
    msg_id = str(msg.message_id)
    state = _get_state(chat_id, state_by_chat)
    _maybe_summarize(chat_id, state)
    _maybe_maintenance(chat_id, state)

    ctx_cfg = ContextConfig(
        recent_limit=int(os.getenv("RECENT_LIMIT", "40")),
        summary_days=int(os.getenv("SUMMARY_DAYS", "7")),
        max_summary_chars=int(os.getenv("SUMMARY_MAX_CHARS", "2000")),
        system_prompt=SYSTEM_PROMPT,
    )
    ctx = build_context(chat_id, text, store, ctx_cfg)

    raw_block = os.getenv("HUMOR_BLOCK_KEYWORDS", "").strip()
    block_keywords = tuple(
        k.strip().lower() for k in raw_block.split(",") if k.strip()
    )
    humor_cfg = HumorConfig(
        humor_rate=float(os.getenv("HUMOR_RATE", "0.2")),
        min_gap_seconds=int(os.getenv("HUMOR_MIN_GAP_SECONDS", "180")),
        min_length=int(os.getenv("HUMOR_MIN_LENGTH", "6")),
        max_length=int(os.getenv("HUMOR_MAX_LENGTH", "600")),
        block_keywords=block_keywords,
    )
    if should_add_humor(text, state.last_humor_ts, humor_cfg):
        ctx["messages"].append(
            {
                "role": "system",
                "content": "Ð•ÑÐ»Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾, Ð´Ð¾Ð±Ð°Ð²ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ ÑˆÑƒÑ‚ÐºÑƒ Ð¸Ð»Ð¸ Ð»Ñ‘Ð³ÐºÐ¸Ð¹ Ð¿Ð¾Ð´ÐºÐ¾Ð» Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.",
            }
        )
        state.last_humor_ts = time.time()

    store.add_message(chat_id, msg_id, "user", text)

    start_time = time.time()
    async with aiohttp.ClientSession() as session:
        if USE_CHAT_API:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ chat API Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
            async with session.post(f"{OLLAMA}/api/chat", json={
                "model": MODEL,
                "messages": ctx["messages"],
                "stream": False,
                "temperature": 0.7,
            }) as r:
                data = await r.json()
                reply = data.get("message", {}).get("content", "â€¦")
        else:
            # Fallback Ð½Ð° generate API Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð¼
            async with session.post(f"{OLLAMA}/api/generate", json={
                "model": MODEL,
                "prompt": ctx["messages"][-1]["content"],
                "system": ctx["messages"][0]["content"],
                "stream": False,
                "temperature": 0.7,
            }) as r:
                data = await r.json()
                reply = data.get("response", "â€¦")
    
    response_time = time.time() - start_time
    print(f"Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°: {response_time:.2f} ÑÐµÐº")
    
    store.add_message(chat_id, msg_id + ":assistant", "assistant", reply)
    _maybe_maintenance(chat_id, state)
    await msg.answer(reply)

async def main() -> None:
    global BOT_ID
    me = await bot.get_me()
    BOT_ID = me.id
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
